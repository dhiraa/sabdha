{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# More To Come. Stay Tuned. !!\nIf there are any suggestions/changes you would like to see in the Kernel please let me know :). Appreciate every ounce of help!\n\n**This notebook will always be a work in progress**. Please leave any comments about further improvements to the notebook! Any feedback or constructive criticism is greatly appreciated!. **If you like it or it helps you , you can upvote and/or leave a comment :).**|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "from tqdm import tqdm_notebook\n",
    "import wave\n",
    "from scipy.io import wavfile\n",
    "SAMPLE_RATE = 44100\n",
    "\n",
    "import seaborn as sns # for making plots with seaborn\n",
    "color = sns.color_palette()\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "offline.init_notebook_mode()\n",
    "import plotly.tools as tls\n",
    "# Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d076fa89-24f4-4759-bacf-a4307dcbe335",
    "_uuid": "88bd76ba9e930d1ad9930258df649dbf99fd78fa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "facd7844-7323-4928-bcb8-813cbc1ba359",
    "_uuid": "a28aaab7d3a0df35d309b54698c8dc1572db8f48",
    "collapsed": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "INPUT_LIB = '../input/'\n",
    "audio_train_files = os.listdir('../input/audio_train')\n",
    "audio_test_files = os.listdir('../input/audio_test')\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "submission = pd.read_csv(\"../input/sample_submission.csv\", index_col='fname')\n",
    "train_audio_path = '../input/audio_train/'\n",
    "filename = '/001ca53d.wav' # Hi-hat\n",
    "sample_rate, samples = wavfile.read(str(train_audio_path) + filename)\n",
    "#sample_rate = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "64f8b20e-a00e-4a63-8e36-4ffc1672bf5d",
    "_uuid": "cc67aae1064845f6e4fb9dc6d280fcc030c29896",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ddf7e577-44e7-4f14-9b33-1b02290df07c",
    "_uuid": "3675492f1b0003194863afd644345d83b903ae6e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Size of training data\",train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f0b4e979-d1ee-4cb3-b0a0-3a135f07560b",
    "_uuid": "e8b1353be31acaa7ba459b38de2cc13eea6bf5c1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "68f69c7a-4e4b-4ded-beb2-f79289d949f3",
    "_uuid": "1650e26b48ec4bd5211a9e86d6d4df3fe2bb35b6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eee31195-7184-42e2-a5b7-be186a9b3463",
    "_uuid": "7c4d83989143944324fa8a74dc1763336c93e443",
    "collapsed": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_filename(fname, string):   \n",
    "    file_name = fname.split('/')[1]\n",
    "    if file_name[:2] == '__':        \n",
    "        file_name = string + file_name\n",
    "    return file_name\n",
    "\n",
    "def load_wav_file(name, path):\n",
    "    _, b = wavfile.read(path + name)\n",
    "    assert _ == SAMPLE_RATE\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "48dac2d9-f6ee-4742-8a6f-73aede99cb5a",
    "_uuid": "b95dc3806ce0bba677b545d559aae14c14ca403c",
    "collapsed": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame({'file_name' : train['fname'],\n",
    "                         'target' : train['label']})   \n",
    "train_data['time_series'] = train_data['file_name'].apply(load_wav_file, \n",
    "                                                      path=INPUT_LIB + 'audio_train/')    \n",
    "train_data['nframes'] = train_data['time_series'].apply(len)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b19dc0a1-ff5f-4a7e-82da-763cfb2d5e03",
    "_uuid": "0c3d95b061d382e5a591140e1df03f6949289c07",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dfaf585f-83a8-459a-84d5-d671036e10a8",
    "_uuid": "6741e54479b6c13d002b519a99580428dbf49ee4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Size of training data after some preprocessing : \",train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5afb2f4f-1204-431b-be96-61e6efdd89ac",
    "_uuid": "5b528668917c289337d3a7a91d3733b7b86b2db1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# missing data in training data set\n",
    "total = train_data.isnull().sum().sort_values(ascending = False)\n",
    "percent = (train_data.isnull().sum()/train_data.isnull().count()).sort_values(ascending = False)\n",
    "missing_train_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2758351a-96d0-47f9-9a4c-a8d6cc789714",
    "_uuid": "f9a63e51ff9713b18da868b489cb005cbda2aab8"
   },
   "source": [
    "There is no missing data in training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5bfdf7e2-f5f1-4071-969f-d18490fa00ac",
    "_uuid": "d073a9a680be0490484a730755bb41fe66155e63"
   },
   "source": [
    "# Manually verified Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "486ee274-8363-4062-8aba-7398b7168511",
    "_uuid": "f3dce38ad267d50d4149791d1d95a209f3f8b235",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "temp = train['manually_verified'].value_counts()\n",
    "labels = temp.index\n",
    "sizes = (temp / temp.sum())*100\n",
    "trace = go.Pie(labels=labels, values=sizes, hoverinfo='label+percent')\n",
    "layout = go.Layout(title='Manually varification of labels(0 - No, 1 - Yes)')\n",
    "data = [trace]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fd1b2bb1-bd10-4a98-b996-fa384ac9a67b",
    "_uuid": "50badabfc75717ebe4bae3201f8342f1ed456620"
   },
   "source": [
    "* Approximately 40 % labels are manually varified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b6089cdb-1551-49e0-9f9c-40f6273a7d35",
    "_uuid": "a6d2b3a1bec8c7246f22e857841b5f8edc034c2d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(train_data.nframes.values, bins=50, kde=False)\n",
    "plt.xlabel('nframes', fontsize=12)\n",
    "plt.title(\"Histogram of #frames\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2cabc2ce-e532-4d2c-89cb-7b0ec940ac96",
    "_uuid": "8f47d6f330c636dce18c545b953435f8caa6bc72",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,8))\n",
    "boxplot = sns.boxplot(x=\"target\", y=\"nframes\", data=train_data)\n",
    "boxplot.set(xlabel='', ylabel='')\n",
    "plt.title('Distribution of audio frames, per label', fontsize=17)\n",
    "plt.xticks(rotation=80, fontsize=17)\n",
    "plt.yticks(fontsize=17)\n",
    "plt.xlabel('Label name')\n",
    "plt.ylabel('nframes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1d0958c2-ddc8-40b7-951a-fe42d0e942c9",
    "_uuid": "a90f8969b4efa3f22f8cfc2dfb8a5ff016146934",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Total number of labels in training data : \",len(train_data['target'].value_counts()))\n",
    "print(\"Labels are : \", train_data['target'].unique())\n",
    "plt.figure(figsize=(15,8))\n",
    "audio_type = train_data['target'].value_counts().head(30)\n",
    "sns.barplot(audio_type.values, audio_type.index)\n",
    "for i, v in enumerate(audio_type.values):\n",
    "    plt.text(0.8,i,v,color='k',fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Label Name')\n",
    "plt.title(\"Top 30 labels with their frequencies in training data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "26b351d7-3d22-4fe6-be72-27256b2f0bef",
    "_uuid": "f01835ce7bd18bdd78f0c1ad098b90ee205bdfc5"
   },
   "source": [
    "### Total number of labels are 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f905104a-3756-4ad8-bcb5-538ae9581cde",
    "_uuid": "c221e583802c1a22820f2712bf95b2054cbd928a",
    "collapsed": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "temp = train_data.sort_values(by='target')\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1240a3c5-8de3-4d16-bf5e-a9fe86b8648c",
    "_uuid": "bf0f38c4747a77d54ee7e80d8e1f0f9ed603d953"
   },
   "source": [
    "## Now look at  some labels waveform :\n  1. Acoustic_guitar\n  2. Applause\n  3. Bark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5720e77c-7934-4f46-8ad1-c3e57185a776",
    "_uuid": "f626d7a620064fbc1dccb5c4dae5dc841e987d64"
   },
   "source": [
    "## 1. Acoustic_guitar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a8c785a1-527e-4bd0-93bc-d093846672dc",
    "_uuid": "c1507df985eca825fcd7ad70a71a5c0154907e95",
    "collapsed": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Acoustic_guitar : \")\n",
    "fig, ax = plt.subplots(10, 4, figsize = (12, 16))\n",
    "for i in range(40):\n",
    "    ax[i//4, i%4].plot(temp['time_series'][i])\n",
    "    ax[i//4, i%4].set_title(temp['file_name'][i][:-4])\n",
    "    ax[i//4, i%4].get_xaxis().set_ticks([])\n",
    "fig.savefig(\"AudioWaveform\", dpi=900)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6e41fd2d-d0d8-456e-b029-e1df5e7088d7",
    "_uuid": "c2c66d8575d54116db171350958d28bf733048a5"
   },
   "source": [
    "## 2. Applause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "df1a02cb-fd5c-4b2a-be6f-cce5ef6495d6",
    "_uuid": "258e0c112bb554d0b003fa613b2d5c9919176a56",
    "collapsed": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Applause : \")\n",
    "fig, ax = plt.subplots(10, 4, figsize = (12, 16))\n",
    "for i in range(40):\n",
    "    ax[i//4, i%4].plot(temp['time_series'][i+300])\n",
    "    ax[i//4, i%4].set_title(temp['file_name'][i+300][:-4])\n",
    "    ax[i//4, i%4].get_xaxis().set_ticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7bd366f9-68c9-44e8-b8ef-1bb77ba8de4a",
    "_uuid": "b5d800ea2116bb7273f0b1e854dd61d11da5ff99"
   },
   "source": [
    "## 3. Bark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2850468b-84bc-4440-88e8-dde6f5ffd649",
    "_uuid": "d2d02f8cf49eb86ae91791c5aac78b69a37913b9",
    "collapsed": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Bark : \")\n",
    "fig, ax = plt.subplots(10, 4, figsize = (12, 16))\n",
    "for i in range(40):\n",
    "    ax[i//4, i%4].plot(temp['time_series'][i+600])\n",
    "    ax[i//4, i%4].set_title(temp['file_name'][i+600][:-4])\n",
    "    ax[i//4, i%4].get_xaxis().set_ticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "42b656d6-65f2-486a-9e24-13cb8868a93b",
    "_uuid": "42494f1e0dccd9c4f5a0304b006a8904ce4231ad",
    "collapsed": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud(max_font_size=50, width=600, height=300).generate(' '.join(train_data.target))\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.title(\"Wordcloud for Labels\", fontsize=35)\n",
    "plt.axis(\"off\")\n",
    "plt.show() \n",
    "#fig.savefig(\"LabelsWordCloud\", dpi=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6466b131-c6a0-44d5-8d1e-98b55af08acc",
    "_uuid": "8d7efdc223566e72bc9d345b5e7090b9b5d09a2a"
   },
   "source": [
    "# Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "85bba67f-297d-4879-ad92-9479e609eb9d",
    "_uuid": "b375d512e1bff6c57432b22ea6332106eba739dd",
    "collapsed": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "32779efc-4d40-47a9-ac77-92746ded35eb",
    "_uuid": "4436a296b711333a93f207e517aa2e89f21cbd22",
    "collapsed": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "freqs, times, spectrogram = log_specgram(samples, sample_rate)\n",
    "\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "ax2 = fig.add_subplot(211)\n",
    "ax2.imshow(spectrogram.T, aspect='auto', origin='lower', \n",
    "           extent=[times.min(), times.max(), freqs.min(), freqs.max()])\n",
    "ax2.set_yticks(freqs[::40])\n",
    "ax2.set_xticks(times[::40])\n",
    "ax2.set_title('Spectrogram of Hi-hat ' + filename)\n",
    "ax2.set_ylabel('Freqs in Hz')\n",
    "ax2.set_xlabel('Seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "68d18fde-7dec-454b-8242-7c03a0c1e68c",
    "_uuid": "dc6e1989c13b7bde66563d6973615dcbe17678a7"
   },
   "source": [
    "# Specgtrogram of \"Hi-Hat\" in 3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4337f736-0a55-4a25-850d-34831657c029",
    "_uuid": "80bbd320562b1aad3938ae49ea5ce418c9eba234"
   },
   "source": [
    "If we use spectrogram as an input features for NN, we have to remember to normalize features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a9612a73-1416-4154-b973-2503a40a3dbb",
    "_uuid": "c924a77c44e2ed82459c66d1f3387ea7a8a4212f",
    "collapsed": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mean = np.mean(spectrogram, axis=0)\n",
    "std = np.std(spectrogram, axis=0)\n",
    "spectrogram = (spectrogram - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f0159688-cd2a-4a1e-8fd9-3d3c37672b68",
    "_uuid": "aa53ec594ded78fff8c84ee18404fad685b26f96",
    "collapsed": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = [go.Surface(z=spectrogram.T)]\n",
    "layout = go.Layout(\n",
    "    title='Specgtrogram of \"Hi-Hat\" in 3d',\n",
    "    scene = dict(\n",
    "    yaxis = dict(title='Frequencies', range=freqs),\n",
    "    xaxis = dict(title='Time', range=times),\n",
    "    zaxis = dict(title='Log amplitude'),\n",
    "    ),\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2a2a29f1-5063-44be-8c49-67b64e2464c3",
    "_uuid": "c225bb6c18b308060b80766dccd19cf9b31a4f5f",
    "collapsed": true
   },
   "source": [
    "# More To Come. Stayed Tuned !!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
